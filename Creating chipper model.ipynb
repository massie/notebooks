{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_training_data = pd.DataFrame.from_csv(\"/workspace/notebooks_data/training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read and return the Saxon test set \n",
    "def fetch_testing_data():\n",
    "    df = pd.DataFrame.from_csv(\"data/proteasomal_cleavage/s6_in_vivo_mhc_1_ligands_dataset.csv\")\n",
    "    df = df[[\"Sequences\", \"Activity\"]]\n",
    "    df.columns = [\"sequence\", \"is_cleaved\"]\n",
    "    df.is_cleaved[df.is_cleaved == -1] = 0\n",
    "    return df\n",
    "\n",
    "raw_testing_data = fetch_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49116 training samples before removing the Saxova sequences.\n",
      "There are 49116 training samples after filtering out Saxova.\n",
      "Final training set has 49113 samples of 49116 raw samples.\n",
      "Final testing set has 416 samples of 419 raw samples.\n"
     ]
    }
   ],
   "source": [
    "from aa_props import seq_to_aa_props\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# We need to remove the Saxova samples from our training set\n",
    "print \"There are %d training samples before removing the Saxova sequences.\" % (\n",
    "    raw_training_data.shape[0])\n",
    "raw_training_data = raw_training_data[raw_training_data.sequence.isin(\n",
    "    raw_testing_data.sequence) == False]\n",
    "print \"There are %d training samples after filtering out Saxova.\" % (\n",
    "    raw_training_data.shape[0])\n",
    "\n",
    "# Filter to check for selenocysteine (TODO) and an invalid \"'\"\n",
    "train_seq_validator = lambda seq: seq.find(\"U\") == -1 and seq.find(\"'\") == -1\n",
    "# Testing set has two sample which are not the correct len, filter them out too\n",
    "test_seq_validator = lambda seq: train_seq_validator(seq) and len(seq) == 28\n",
    "\n",
    "process_raw_data = lambda data, is_valid: [(seq_to_aa_props(seq), is_cleaved)\n",
    "             for (i, seq, is_cleaved) in data.itertuples()\n",
    "             if is_valid(seq)]\n",
    "\n",
    "# Filter AA seqs and expand to AA features\n",
    "scaler = MinMaxScaler()\n",
    "training_X_y = process_raw_data(raw_training_data, train_seq_validator)\n",
    "testing_X_y = process_raw_data(raw_testing_data, test_seq_validator)\n",
    "\n",
    "(training_X, training_y) = zip(*training_X_y)\n",
    "(testing_X, testing_y) = zip(*testing_X_y)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "training_X = scaler.fit_transform(training_X)\n",
    "testing_X = scaler.transform(testing_X)\n",
    "\n",
    "print \"Final training set has %d samples of %d raw samples.\" % (\n",
    "    training_X.shape[0], raw_training_data.shape[0])\n",
    "print \"Final testing set has %d samples of %d raw samples.\" % (\n",
    "    testing_X.shape[0], raw_testing_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import svm\n",
    "#\n",
    "#l = svm.LinearSVC(dual=False)\n",
    "#model = l.fit(training_X, training_y)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from util.roc_curve import roc_curve\n",
    "#from sklearn.metrics import classification_report\n",
    "#%matplotlib notebook\n",
    "\n",
    "#predicted_y = model.predict(testing_X)\n",
    "#print classification_report(testing_y, predicted_y)\n",
    "#roc_curve(testing_y, predicted_y)\n",
    "\n",
    "#print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file = \"/workspace/notebooks_data/training_data.ll\"\n",
    "test_file = \"/workspace/notebooks_data/testing_data.ll\"\n",
    "\n",
    "def create_liblinear_files():\n",
    "    for (outpath, rows) in [(train_file, zip(training_y, training_X)),\n",
    "                            (test_file, zip(testing_y, testing_X))]:\n",
    "        with open(outpath, 'w') as out:\n",
    "            for (is_cleaved, features) in rows:\n",
    "                out.write(\"%+d \" % (is_cleaved))\n",
    "                for (feature_id, feature_value) in enumerate(features):\n",
    "                    out.write(\"%d:%s \" % (feature_id + 1, feature_value))\n",
    "                out.write(\"\\n\")\n",
    "\n",
    "create_liblinear_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing parameter search with 5-fold cross validation.\n",
      "log2c= -25.00\trate=69.4114\n",
      "log2c= -24.00\trate=70.3744\n",
      "log2c= -23.00\trate=72.5103\n",
      "log2c= -22.00\trate=75.2306\n",
      "log2c= -21.00\trate=77.7289\n",
      "log2c= -20.00\trate=79.4678\n",
      "log2c= -19.00\trate=80.3616\n",
      "log2c= -18.00\trate=80.7444\n",
      "log2c= -17.00\trate=81.0519\n",
      "log2c= -16.00\trate=81.3471\n",
      "log2c= -15.00\trate=81.795\n",
      "log2c= -14.00\trate=82.3937\n",
      "log2c= -13.00\trate=83.2142\n",
      "log2c= -12.00\trate=84.1895\n",
      "log2c= -11.00\trate=85.0651\n",
      "log2c= -10.00\trate=85.8408\n",
      "log2c=  -9.00\trate=86.6247\n",
      "log2c=  -8.00\trate=87.2009\n",
      "log2c=  -7.00\trate=87.6978\n",
      "log2c=  -6.00\trate=87.9706\n",
      "log2c=  -5.00\trate=88.3167\n",
      "log2c=  -4.00\trate=88.4715\n",
      "log2c=  -3.00\trate=88.5651\n",
      "log2c=  -2.00\trate=88.5651\n",
      "log2c=  -1.00\trate=88.5651\n",
      "log2c=   0.00\trate=88.5651\n",
      "Best C = 0.125  CV accuracy = 88.5651%\n"
     ]
    }
   ],
   "source": [
    "findC = !train -C -s 0 $train_file\n",
    "print \"\\n\".join(findC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C=0.125 to create the model from /workspace/notebooks_data/training_data.ll\n",
      "iter  1 act 1.970e+03 pre 1.720e+03 delta 2.282e+00 f 4.255e+03 |g| 2.572e+03 CG   5\n",
      "cg reaches trust region boundary\n",
      "iter  2 act 4.260e+02 pre 3.497e+02 delta 2.945e+00 f 2.286e+03 |g| 8.400e+02 CG  10\n",
      "cg reaches trust region boundary\n",
      "iter  3 act 1.437e+02 pre 1.224e+02 delta 3.599e+00 f 1.860e+03 |g| 2.736e+02 CG  12\n",
      "cg reaches trust region boundary\n",
      "iter  4 act 4.423e+01 pre 4.098e+01 delta 3.913e+00 f 1.716e+03 |g| 8.934e+01 CG  24\n",
      "iter  5 act 1.900e+00 pre 1.863e+00 delta 3.913e+00 f 1.672e+03 |g| 3.556e+01 CG  23\n"
     ]
    }
   ],
   "source": [
    "bestC = findC[-1].split(\" \")[3]\n",
    "print \"Using C=%s to create the model from %s\" % (bestC, train_file)\n",
    "createModel = !train -c {bestC} -s 0 {train_file} {train_file}.model\n",
    "print \"\\n\".join(createModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: use trainging_data_scale to generate C matrix for AA features"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
