{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example of a neural network written in Octave/Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function y = sigmoid(x, derivative=false)\n",
    "        if (derivative) \n",
    "                y = x.*(1-x);\n",
    "        else\n",
    "                y = 1.0 ./ (1.0 + exp(-x));\n",
    "        endif\n",
    "endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function theta = theta_init(in_size, out_size, epsilon = 0.12)\n",
    "        theta = rand(out_size, in_size +1) * 2 * epsilon - epsilon;\n",
    "endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function [theta1, theta2] = nn_train(X, y, desired_error, max_iterations = 100000, epsilon = 0.12, hidden_nodes = 0)\n",
    "\n",
    "        m = size(X, 1);\n",
    "        input_nodes = size(X, 2);\n",
    "        output_nodes = size(y, 2);\n",
    "        if (hidden_nodes <= 0)\n",
    "                hidden_nodes = floor(input_nodes * 2 / 3 + output_nodes);\n",
    "        endif\n",
    "        theta1 = theta_init(input_nodes, hidden_nodes, epsilon)';\n",
    "        theta2 = theta_init(hidden_nodes, output_nodes, epsilon)';\n",
    "\n",
    "        % Move constants outside of the loop\n",
    "        % The first activation layer is constant\n",
    "        a1 = [ones(size(X, 1), 1) X];\n",
    "        % The bias unit ones are constant too\n",
    "        a2_ones = ones(size(a1, 1), 1);\n",
    "\n",
    "        printf(\"Training the neural network (%d input, %d hidden, %d output nodes) with %d observations\\n\", ...\n",
    "                        input_nodes, hidden_nodes, output_nodes, m);\n",
    "\n",
    "        tic_id = tic();\n",
    "\n",
    "        for k = 1:max_iterations\n",
    "                % Feed forward\n",
    "                a2 = [a2_ones sigmoid( a1 * theta1 )];\n",
    "                a3 = sigmoid( a2 * theta2 );\n",
    "\n",
    "                a3_delta = y - a3;\n",
    "\n",
    "                % Each second report the current state to the user\n",
    "                if (toc(tic_id) > 1)\n",
    "                        meansq_error = mean(meansq(a3_delta));\n",
    "                        printf(\"Iteration: %9d (max:%d), mse: %9f (target:%f)\\n\", ...\n",
    "                                k, max_iterations, meansq_error, desired_error);\n",
    "                        tic_id = tic();\n",
    "                        if (meansq_error < desired_error)\n",
    "                                break\n",
    "                        endif\n",
    "                endif\n",
    "\n",
    "                % Backpropagation\n",
    "                a2_error = a3_delta * theta2';\n",
    "                a2_delta = a2_error .* sigmoid(a2, true);\n",
    "\n",
    "                theta2 += ((a2' * a3_delta) ./ m);\n",
    "                theta1 += ((a1' * a2_delta) ./ m)(:, 2:end);\n",
    "        endfor\n",
    "\n",
    "endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function a3 = nn_predict(X, theta1, theta2)\n",
    "        a2 = sigmoid([ones(size(X, 1), 1) X] * theta1);\n",
    "        a3 = sigmoid([ones(size(X, 1), 1) a2] * theta2);\n",
    "endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the neural network (2 input, 2 hidden, 1 output nodes) with 4 observations\n",
      "Iteration:      7930 (max:100000), mse:  0.250000 (target:0.000100)\n",
      "Iteration:     15790 (max:100000), mse:  0.000060 (target:0.000100)\n",
      "\n",
      "\n",
      "      Input Values   Predicted   Actual\n",
      "   0.00000   0.00000   0.00741   0.00000\n",
      "   0.00000   1.00000   0.99306   1.00000\n",
      "   1.00000   0.00000   0.99010   1.00000\n",
      "   1.00000   1.00000   0.00636   0.00000\n",
      "\n",
      "Mean square error of trained model predictions: 0.000060\n"
     ]
    }
   ],
   "source": [
    "X = [0 0; 0 1; 1 0; 1 1];\n",
    "y = [0; 1; 1; 0];\n",
    "\n",
    "[theta1, theta2] = nn_train(X, y, 0.0001);\n",
    "\n",
    "pred_values = nn_predict(X, theta1, theta2);\n",
    "printf(\"\\n\\n      Input Values   Predicted   Actual\\n\");\n",
    "disp([X pred_values y])\n",
    "printf(\"\\nMean square error of trained model predictions: %f\\n\", mean(meansq(y - pred_values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "0.16.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
